Project Overview

This project is a web-based news credibility assessment platform designed to help users evaluate the trustworthiness of news articles using transparent credibility signals, community feedback, and AI-assisted analysis.
The platform does not claim to decide absolute truth. Instead, it exposes why an article or source may or may not deserve trust, aligning with SDG-16 (Peace, Justice, and Strong Institutions) by promoting transparency, accountability, and media literacy.
The system aggregates news articles automatically and accepts user-submitted articles, applies a multi-factor credibility pipeline, and presents results through an intuitive, explainable UI.

2. Core Design Principles
Credibility ‚â† Truth
The platform provides credibility indicators, not factual verdicts.
Explainability First
Every score must be broken down and auditable.
Manipulation Resistance
Community input is weighted and guarded against spam and brigading.
Scalable Architecture
Frontend, backend, and AI logic are modular and independently scalable.
Judge-Friendly Execution
Clean UI, clear workflows, disciplined Git usage, and working features matter more than overcomplex ML.

3. How Articles Enter the Platform (Ingestion Model)
The platform uses a hybrid ingestion model:

A. System-Aggregated Articles
Backend periodically fetches articles from predefined RSS feeds (e.g., reputable news outlets).
Each fetched article automatically becomes a post in the system.
Initial credibility state: Under Review (neutral baseline).

B. User-Submitted Articles
Authenticated users can submit an article by pasting a URL.
The system extracts article content and metadata.
Duplicate detection prevents repeated entries.
User-submitted articles are clearly marked and also start as Under Review.
Both types of articles go through the same credibility evaluation pipeline.

4. User Roles
Regular User
View articles and credibility analysis
Rate credibility
Comment with structured reasons
Report misclassifications
Build credibility over time

Trusted User
Same as regular user but with higher vote weight due to historical reliability

Admin
Review flagged articles and users
Manage sources
Override credibility scores (with justification)
Enforce soft locks and bans

5. Credibility Evaluation System
Each article is evaluated using a multi-factor credibility engine.
Credibility Factors
Source Credibility Score (historical performance of the source)
Community Feedback Score (weighted user opinions)
NLP Language Analysis Score (sensationalism vs factual tone)
Cross-Source Corroboration Score (independent confirmation)
Spam / Manipulation Penalty
The final score is a weighted combination of these factors and is always accompanied by a visual breakdown (pie chart).

6. Credibility Status States
Each article has a status, separate from its numeric score:
üü° Under Review ‚Äî Low data or suspicious activity detected
üü¢ Widely Corroborated ‚Äî Supported by multiple credible sources
üî¥ High Risk / Contested ‚Äî Conflicting reports or manipulation indicators
Status exists to prevent false certainty and handle breaking news responsibly.

7. Community Trust & User Weighting
Not all opinions are equal.
Each user has a credibility score that determines vote weight.

Credibility is:
Built through accurate ratings
Reduced by rejected reports or spam behavior
Credibility is category-specific (e.g., finance, geopolitics).
Vote weight = base weight √ó category credibility √ó reliability factor.
Users have a Credibility Profile showing their trust level and history.

8. Anti-Manipulation & Spam Detection
The system actively detects coordinated abuse using rule-based logic:
IP and subnet clustering
Sudden time-based voting spikes
New-account mass activity

Extreme-only voting patterns
When detected:
Votes are down-weighted
Article enters Soft Lock
Banner is shown: ‚ÄúCredibility under verification due to unusual activity‚Äù
Admin review is triggered
No silent deletions; transparency is maintained.

9. Cross-Source Claim Verification
The platform extracts key claims using NLP:
Headline
Named entities
Key statements

It then checks:
How many independent domains report the same claim

Displays:
Number of supporting sources
Clickable reference links
Source credibility badges
This reinforces trust through independent corroboration, not popularity.

10. NLP-Based Article Analysis
AI is used for assistive analysis, not verdicts.
NLP Capabilities
Detect emotionally charged / sensational language
Highlight fact-based sentences (numbers, entities, verifiable data)
Compute Fact vs Opinion Ratio

UI Representation
üî¥ Red highlights ‚Üí hype / emotional manipulation
üü¢ Green highlights ‚Üí factual statements

Legend shown alongside article
This visually demonstrates AI value during demos.

11. Transparency & Auditability
Every credibility change is recorded in an audit log:

What changed
Why it changed
When it changed

Admins can override scores, but:
Must provide justification
Action is visible in the audit trail
This reinforces institutional accountability.

12. UI / UX Flow Summary
Landing Page: News feed with credibility badges

Article Page:
Credibility score ‚Üí breakdown ‚Üí cross-source verification ‚Üí NLP-highlighted article

Interaction Modals:
Rate, comment, report (structured, reason-based)

Profiles:
User credibility profiles and source profiles

Admin Dashboard:
Flagged items, spam alerts, moderation controls

UI prioritizes clarity, color coding, and minimal cognitive load.

13. Architecture Overview
Components
Frontend: Web app (React/Next.js)
Backend API: Auth, credibility logic, moderation
AI/NLP Module: Language analysis and claim extraction
Database: PostgreSQL (core data)
Cache: Redis (credibility scores)
Background Workers: Scraping, NLP processing
The system is modular, horizontally scalable, and hackathon-safe.

14. Git & Development Discipline
Feature-based branching
Mandatory pull requests
Meaningful commits by all team members
Clean README with architecture diagrams and explanations
This is treated as part of the product, not an afterthought.

15. Scope Boundaries (Important)
Explicitly out of scope
Absolute fact-check verdicts
Political bias labeling
Fully automated misinformation detection
Mobile apps
The platform focuses on credible signals, not censorship.

16. Final Positioning Statement
‚ÄúThis platform does not tell users what to believe.
It shows them why something deserves trust ‚Äî or skepticism ‚Äî in a transparent, explainable, and manipulation-resistant way.‚Äù

17. User interaction
"The users can comment on the post, there should also be a upvote and downvote button for the post and the comments.
which will affect the credibility score of the post and the comments."